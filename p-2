from tensorflow.keras.datasets import imdb
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Load the dataset
(train_data, train_label), (test_data, test_label) = imdb.load_data(num_words=10000)

# Function to vectorize sequences
def vectorize_sequences(sequences, dimensions=10000):
    results = np.zeros((len(sequences), dimensions))
    for i, sequence in enumerate(sequences):
        results[i, sequence] = 1
    return results

# Vectorize the input data
x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)

# Convert labels to float32
y_train = np.asarray(train_label).astype('float32')
y_test = np.asarray(test_label).astype('float32')

# Build the model
model = Sequential()
model.add(Dense(16, input_shape=(10000,), activation="relu"))
model.add(Dense(16, activation="relu"))
model.add(Dense(1, activation="sigmoid"))

# Compile the model
model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])

# Model summary
model.summary()

# Train the model
history = model.fit(
    x_train, y_train,
    validation_split=0.3,
    epochs=20,
    batch_size=512,
    verbose=1
)
